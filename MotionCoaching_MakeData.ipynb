{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 자료 형태소 분석 결과 새로 생성\n",
    "\n",
    " * NaturalLanguageData_ToUse.txt 새로 만들었을 경우에만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8233\n",
      "3\n",
      "['11514', '12시 땡!', '0']\n",
      "filepath:  C:\\Users\\NAM WOO JIN\\anaconda3\\lib\\site-packages\n",
      "classpath:  C:\\Users\\NAM WOO JIN\\anaconda3\\lib\\site-packages\\rhinoMorph/lib/rhino.jar\n",
      "JVM is already started~\n",
      "RHINO started!\n",
      "sample data: ['땡', '!']\n",
      "joined sample data: 땡 !\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"C:/Users/NAM WOO JIN/SpeechTextClassifier_hansung\"  #우진 path\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "def read_data(filename, encoding):\n",
    "    \"\"\"읽기 함수\"\"\"\n",
    "    with open(filename, 'r', encoding=encoding) as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]                 # txt 파일의 헤더(id document label)는 제외하기는 1:\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_data(data, filename, encoding):\n",
    "    \"\"\"쓰기 함수\"\"\"\n",
    "    with open(filename, 'w', encoding=encoding) as f:\n",
    "        f.write(data)\n",
    "\n",
    "data = read_data('NaturalLanguageData_ToUse.txt', encoding='cp949')        # 연습파일은 ratings_small.txt  0은 부정, 1은 긍정\n",
    "print(len(data))                                                              # 11513\n",
    "print(len(data[0]))                                                           # 3개의 컬럼으로 나뉘어 있다\n",
    "print(data[0])\n",
    "\n",
    "\n",
    "# 형태소 분석기 기동\n",
    "import rhinoMorph as rhinoMorph\n",
    "rn = rhinoMorph.startRhino()\n",
    "\n",
    "# 형태소 분석된 문장 샘플 보기\n",
    "sample_data = rhinoMorph.onlyMorph_list(rn, data[0][1], pos=['NNG', 'NNP', 'NP', 'VV', 'VA', 'XR', 'VCN', 'MAG', 'MAJ', 'IC', 'JKV', 'EC', 'EF', 'SF'])\n",
    "print('sample data:', sample_data)\n",
    "print('joined sample data:', ' '.join(sample_data))\n",
    "\n",
    "\n",
    "\n",
    "# 전체 문장 형태소 분석\n",
    "morphed_data = ''\n",
    "for data_each in data:\n",
    "    morphed_data_each = rhinoMorph.onlyMorph_list(rn, data_each[1], pos=['NNG', 'NNP', 'NP', 'VV', 'VA', 'XR', 'VCN', 'MAG', 'MAJ', 'IC', 'JKV', 'EF', 'SF'])\n",
    "    joined_data_each = ' '.join(morphed_data_each)                                  # 문자열을 하나로 연결\n",
    "    if joined_data_each:                                                            # 내용이 있는 경우만 저장함\n",
    "        morphed_data += data_each[0]+\"\\t\"+data_each[1]+\"\\t\"+joined_data_each+\"\\t\"+data_each[2]+\"\\n\"\n",
    "\n",
    "\n",
    "# 형태소 분석된 파일 저장\n",
    "os.chdir(path)\n",
    "write_data(morphed_data, 'NaturalLanguageData_ToUse.txt', encoding='cp949')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train , Test 자료 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 공통 요소 ###\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#경로의 \\를 /로 바꾸기, 경로 중 한글이 들어가면 안되는 듯\n",
    "path = \"C:/Users/NAM WOO JIN/SpeechTextClassifier_hansung\" #우진path\n",
    "os.chdir(path)\n",
    "\n",
    "def read_data(filename, encoding):\n",
    "    \"\"\"읽기 함수\"\"\"\n",
    "    with open(filename, 'r', encoding=encoding) as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[0:]                 # txt 파일의 헤더(id document label)는 제외하기는 1:\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_data_list(list, filename, encoding):\n",
    "    \"\"\"쓰기 함수\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in list:\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\n' % (item[0], item[1], item[2], item[3]))\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "### train_test_split() 함수를 이용하여 훈련데이터와 테스트데이터 분리 ###\n",
    "data = read_data('NaturalLanguageData_ToUse.txt', encoding='cp949')\n",
    "train, test, = train_test_split(data, test_size=0.1)\n",
    "\n",
    "write_data_list(list=train, filename='train_NaturalLanguageData.txt', encoding='cp949')\n",
    "write_data_list(list=test, filename='test_NaturalLanguageData.txt', encoding='cp949')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
